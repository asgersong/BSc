\babel@toc {english}{}\relax 
\contentsline {chapter}{\chapternumberline {1}Introduction}{9}{chapter.1}%
\contentsline {section}{\numberline {1.1}Thesis Objectives}{9}{section.1.1}%
\contentsline {section}{\numberline {1.2}Outline}{10}{section.1.2}%
\contentsline {chapter}{\chapternumberline {2}Theoretical Foundations}{11}{chapter.2}%
\contentsline {section}{\numberline {2.1}Linear Algebra in Deep Learning}{11}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Vectors, Matrices, and Tensors}{12}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Matrix Operations}{12}{subsection.2.1.2}%
\contentsline {subsubsection}{Floating-Point Operations}{12}{equation.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Singular Value Decomposition}{12}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Low-Rank Approximation}{13}{subsection.2.1.4}%
\contentsline {subsubsection}{Concept of Low-Rank Approximation}{13}{section*.5}%
\contentsline {subsubsection}{Reduction in Storage}{13}{section*.5}%
\contentsline {subsubsection}{Reduction in Computation for Matrix-Vector Multiplications}{14}{section*.5}%
\contentsline {subsubsection}{Reduction in Computation for Matrix-Matrix Multiplications}{15}{section*.5}%
\contentsline {subsection}{\numberline {2.1.5}Neural Networks in Deep Learning}{15}{subsection.2.1.5}%
\contentsline {subsubsection}{Architecture of Neural Networks}{15}{section*.6}%
\contentsline {subsubsection}{Learning Process}{16}{equation.2.1.4}%
\contentsline {subsubsection}{Optimization and Regularization}{16}{equation.2.1.5}%
\contentsline {subsection}{\numberline {2.1.6}Cosine Similarity}{16}{subsection.2.1.6}%
\contentsline {section}{\numberline {2.2}Understanding LLMs}{16}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}The Concept of LLMs?}{16}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Architecture of LLMs}{17}{subsection.2.2.2}%
\contentsline {subsubsection}{Encoder}{17}{figure.caption.7}%
\contentsline {subsubsection}{Decoder}{18}{figure.caption.7}%
\contentsline {subsubsection}{Attention}{18}{figure.caption.7}%
\contentsline {subsubsection}{Multi-head Attention}{20}{figure.caption.8}%
\contentsline {subsubsection}{Why Transformers?}{21}{figure.caption.9}%
\contentsline {subsection}{\numberline {2.2.3}Training and Fine-Tuning}{21}{subsection.2.2.3}%
\contentsline {chapter}{\chapternumberline {3}Literature Review}{23}{chapter.3}%
\contentsline {section}{\numberline {3.1}Overview of LLMs}{23}{section.3.1}%
\contentsline {section}{\numberline {3.2}Previous Studies on LLM Compression with Low-Rank Approximation}{25}{section.3.2}%
\contentsline {section}{\numberline {3.3}Retrieval-Augmented Generation}{25}{section.3.3}%
\contentsline {section}{\numberline {3.4}The BART Model}{26}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Architecture and Training}{27}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Efficacy and Applications}{27}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Evaluating Summarization with ROUGE}{27}{section.3.5}%
\contentsline {paragraph}{ROUGE Metrics}{28}{section.3.5}%
\contentsline {paragraph}{Application and Relevance}{28}{section.3.5}%
\contentsline {paragraph}{Significance in LLM Research}{28}{section.3.5}%
\contentsline {chapter}{\chapternumberline {4}Methodology}{29}{chapter.4}%
\contentsline {section}{\numberline {4.1}RAG Chatbot: Study Buddy}{29}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Development and Environment Tools}{30}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Implementation Steps}{30}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Case Study: Low-Rank Approximation of BART model}{31}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Implementation Steps}{31}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Evaluation Metrics}{32}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Appropriate Rank Selection}{33}{subsection.4.2.3}%
\contentsline {chapter}{\chapternumberline {5}Implementation}{35}{chapter.5}%
\contentsline {section}{\numberline {5.1}RAG Chatbot}{35}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Chatbot Interface}{35}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Generator Component}{36}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Retriever Component}{37}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Integration of Generator and Retriever}{39}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}PDF Uploader}{40}{subsection.5.1.5}%
\contentsline {subsection}{\numberline {5.1.6}Deployment}{42}{subsection.5.1.6}%
\contentsline {subsection}{\numberline {5.1.7}Connections}{43}{subsection.5.1.7}%
\contentsline {section}{\numberline {5.2}Case Study: Low-Rank Approximation of BART model}{44}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Importing the Model}{44}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Dataset Preprocessing}{44}{subsection.5.2.2}%
\contentsline {subsubsection}{Importing the Dataset}{44}{section*.17}%
\contentsline {subsubsection}{Setting Maximum Lengths}{45}{listing.7}%
\contentsline {subsubsection}{Preprocessing Function}{45}{listing.8}%
\contentsline {subsubsection}{Applying the Preprocessing Function}{45}{listing.9}%
\contentsline {subsection}{\numberline {5.2.3}Fine-Tuning the Model}{46}{subsection.5.2.3}%
\contentsline {subsection}{\numberline {5.2.4}Custom Layer Implementation}{46}{subsection.5.2.4}%
\contentsline {paragraph}{Initialization}{47}{listing.12}%
\contentsline {paragraph}{Forward Pass}{47}{listing.12}%
\contentsline {subsection}{\numberline {5.2.5}Traversing the Model and Applying Low-Rank Approximation}{48}{subsection.5.2.5}%
\contentsline {subsection}{\numberline {5.2.6}Evaluation}{49}{subsection.5.2.6}%
\contentsline {chapter}{\chapternumberline {6}Results}{51}{chapter.6}%
\contentsline {section}{\numberline {6.1}RAG Chatbot}{51}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Functionality Testing}{51}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Case Study: Impact of Document Insertion on Response Quality}{52}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Case Study: Impact of Document Insertion on Unrelated Query Response}{54}{subsection.6.1.3}%
\contentsline {section}{\numberline {6.2}Case Study: Low Rank Approximation of BART Model}{55}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Fine-tuning the BART Model}{55}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}ROUGE scores}{56}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Computational Efficiency}{57}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}Comparing Summaries}{58}{subsection.6.2.4}%
\contentsline {chapter}{\chapternumberline {7}Discussion}{61}{chapter.7}%
\contentsline {section}{\numberline {7.1}Interpretation of Results}{61}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}RAG Chatbot}{61}{subsection.7.1.1}%
\contentsline {subsubsection}{Specific Topic Queries}{61}{section*.29}%
\contentsline {subsubsection}{Unfamiliar Topics}{62}{section*.29}%
\contentsline {subsubsection}{Impact on Unrelated Queries}{62}{section*.29}%
\contentsline {subsection}{\numberline {7.1.2}Case Study: Low-Rank Approximation of BART Model}{62}{subsection.7.1.2}%
\contentsline {subsubsection}{Fine-Tuning and Evaluation}{62}{section*.30}%
\contentsline {subsubsection}{Performance Retention}{63}{section*.30}%
\contentsline {subsubsection}{Computational Efficiency}{63}{section*.30}%
\contentsline {section}{\numberline {7.2}Limitations and Future Work}{63}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}RAG Chatbot}{63}{subsection.7.2.1}%
\contentsline {subsubsection}{Ensuring Data Quality in RAG Implementations}{63}{section*.31}%
\contentsline {subsubsection}{Maintaining Conversation Context}{64}{section*.31}%
\contentsline {subsubsection}{Unrelated Queries}{64}{section*.31}%
\contentsline {subsubsection}{Deployment Scalability}{64}{section*.31}%
\contentsline {subsection}{\numberline {7.2.2}Case Study: Low-Rank Approximation}{64}{subsection.7.2.2}%
\contentsline {subsubsection}{Summarization Quality}{64}{section*.32}%
\contentsline {subsubsection}{Comparative Studies}{65}{section*.32}%
\contentsline {subsubsection}{Dataset and Task Specificity}{65}{section*.32}%
\contentsline {subsubsection}{Computational Resources}{65}{section*.32}%
\contentsline {section}{\numberline {7.3}Conclusion}{65}{section.7.3}%
\contentsline {chapter}{\chapternumberline {8}Conclusion}{67}{chapter.8}%
\contentsline {section}{\numberline {8.1}Summary of Key Findings}{67}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}Theoretical Exploration}{67}{subsection.8.1.1}%
\contentsline {subsection}{\numberline {8.1.2}RAG Chatbot Development}{67}{subsection.8.1.2}%
\contentsline {subsection}{\numberline {8.1.3}Low-Rank Approximation of BART Model}{67}{subsection.8.1.3}%
\contentsline {section}{\numberline {8.2}Contributions to the Field}{68}{section.8.2}%
\contentsline {section}{\numberline {8.3}Recommendations for Future Research}{68}{section.8.3}%
\contentsline {chapter}{Bibliography}{71}{section*.34}%
\contentsline {appendix}{\chapternumberline {A}Educational Synergy in Teaching and Research}{73}{appendix.A}%
\contentsline {appendix}{\chapternumberline {B}Interviews with CLAI Members}{77}{appendix.B}%
\contentsline {appendix}{\chapternumberline {C}Architecture of BART}{81}{appendix.C}%
