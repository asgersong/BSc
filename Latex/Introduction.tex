% \chapter{Introduction}
% Large Language Models (LLMs) have become a cornerstone in the field of natural language processing (NLP) and artificial intelligence (AI), driving significant advancements and innovations. These models are designed to understand, generate, and interpret human language at a level that is increasingly indistinguishable from that of a human being. The development and evolution of LLMs mark a pivotal shift in how machines can learn from and interact with textual data, enabling a plethora of applications ranging from automated text generation to sophisticated conversational agents known as chatbots. 
% This study addresses how linear algebra techniques 

\chapter{Introduction}

Large Language Models (LLMs) have become a cornerstone in the field of natural language processing (NLP) and artificial intelligence (AI), driving significant advancements and innovations. These models are designed to understand, generate, and interpret human language at a level that is increasingly indistinguishable from that of a human being. The development and evolution of LLMs mark a pivotal shift in how machines can learn from and interact with textual data, enabling a plethora of applications ranging from automated text generation to sophisticated conversational agents known as chatbots.
Despite the growing use of AI in software- and computer engineering, there is still a notable disconnect between the core mathematical principles and their practical use in software development. Linear algebra, while fundamental to LLMs, is often not directly linked to its real-world applications for said engineers.

\section{Thesis Objectives}

This thesis aims to bridge the gap between linear algebra concepts taught in the classroom, LLMs, and computer engineering applications. The focus is on acquiring a deeper understanding of the specific linear algebra concepts that underpin LLMs, gaining hands-on experience in working with LLMs, and exploring the integration of classroom-taught linear algebra techniques with the development and optimization of LLMs.

The specific objectives of this bachelor's thesis are as follows:
\begin{enumerate}
    \item \textbf{Theoretical Exploration:} Investigate the mathematics and concepts behind LLMs, emphasizing linear algebraic operations such as matrix multiplication and the Transformer Model architecture that forms the basis for today's state-of-the-art models.
    \item \textbf{Computer Engineering Application:} Develop a Retrieval-Augmented Generation (RAG) chatbot prototype to gain practical experience with LLMs and explore their applications in software engineering education.
    \item \textbf{Research Integration:} Evaluate the effectiveness of low-rank approximation techniques, such as Singular Value Decomposition (SVD), in reducing the computational complexity and storage requirements of the BART model while maintaining performance on a downstream task, such as summarization.
\end{enumerate}

To achieve these objectives, the thesis will explore the theoretical foundations of linear algebra as they apply to LLMs, understand how LLMs are developed and optimized, and assess the impact of low-rank approximation on performance by using objective metrics and qualitative analysis.

\section{Outline}
This thesis is structured as follows. 
Chapter \ref{chap:theoretical_foundations} provides an overview of the fundamental concepts in linear algebra and deep learning, detailing their relevance to the development of LLMs. 
Chapter \ref{chap:literature_review} reviews existing research on LLMs, focusing on optimization techniques and the role of linear algebra in enhancing model performance. 
Chapter \ref{chap:methodology} describes the methodologies employed in the development and evaluation of the RAG chatbot prototype and the application of low-rank approximation to the BART model. 
Chapter \ref{chap:implementation} details the implementation steps of the RAG chatbot and the low-rank approximation case study, highlighting key technical aspects and challenges. 
Chapter \ref{chap:evaluation_and_results} presents the results of the empirical evaluations, discussing the impact of the optimization techniques on model performance and computational efficiency. 
Chapter \ref{chap:discussion} interprets the findings, considering the broader implications for the field of NLP and AI, and identifies potential areas for future research. 
Chapter \ref{chap:conclusion} summarizes the key contributions of the thesis, reflects on the research objectives, and provides recommendations for future work.