% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{none/global//global/global}
  \entry{vaswani2023attention}{misc}{}
    \name{author}{8}{}{%
      {{hash=VA}{%
         family={Vaswani},
         familyi={V\bibinitperiod},
         given={Ashish},
         giveni={A\bibinitperiod},
      }}%
      {{hash=SN}{%
         family={Shazeer},
         familyi={S\bibinitperiod},
         given={Noam},
         giveni={N\bibinitperiod},
      }}%
      {{hash=PN}{%
         family={Parmar},
         familyi={P\bibinitperiod},
         given={Niki},
         giveni={N\bibinitperiod},
      }}%
      {{hash=UJ}{%
         family={Uszkoreit},
         familyi={U\bibinitperiod},
         given={Jakob},
         giveni={J\bibinitperiod},
      }}%
      {{hash=JL}{%
         family={Jones},
         familyi={J\bibinitperiod},
         given={Llion},
         giveni={L\bibinitperiod},
      }}%
      {{hash=GAN}{%
         family={Gomez},
         familyi={G\bibinitperiod},
         given={Aidan\bibnamedelima N.},
         giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod},
      }}%
      {{hash=KL}{%
         family={Kaiser},
         familyi={K\bibinitperiod},
         given={Lukasz},
         giveni={L\bibinitperiod},
      }}%
      {{hash=PI}{%
         family={Polosukhin},
         familyi={P\bibinitperiod},
         given={Illia},
         giveni={I\bibinitperiod},
      }}%
    }
    \strng{namehash}{VA+1}
    \strng{fullhash}{VASNPNUJJLGANKLPI1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2017}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 1706.03762
    \endverb
    \field{title}{Attention Is All You Need}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2017}
  \endentry

  \entry{hu2021lora}{misc}{}
    \name{author}{8}{}{%
      {{hash=HEJ}{%
         family={Hu},
         familyi={H\bibinitperiod},
         given={Edward\bibnamedelima J.},
         giveni={E\bibinitperiod\bibinitdelim J\bibinitperiod},
      }}%
      {{hash=SY}{%
         family={Shen},
         familyi={S\bibinitperiod},
         given={Yelong},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=WP}{%
         family={Wallis},
         familyi={W\bibinitperiod},
         given={Phillip},
         giveni={P\bibinitperiod},
      }}%
      {{hash=AZZ}{%
         family={Allen-Zhu},
         familyi={A\bibinithyphendelim Z\bibinitperiod},
         given={Zeyuan},
         giveni={Z\bibinitperiod},
      }}%
      {{hash=LY}{%
         family={Li},
         familyi={L\bibinitperiod},
         given={Yuanzhi},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=WS}{%
         family={Wang},
         familyi={W\bibinitperiod},
         given={Shean},
         giveni={S\bibinitperiod},
      }}%
      {{hash=WL}{%
         family={Wang},
         familyi={W\bibinitperiod},
         given={Lu},
         giveni={L\bibinitperiod},
      }}%
      {{hash=CW}{%
         family={Chen},
         familyi={C\bibinitperiod},
         given={Weizhu},
         giveni={W\bibinitperiod},
      }}%
    }
    \strng{namehash}{HEJ+1}
    \strng{fullhash}{HEJSYWPAZZLYWSWLCW1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2021}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 2106.09685
    \endverb
    \field{title}{LoRA: Low-Rank Adaptation of Large Language Models}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2021}
  \endentry

  \entry{valipour-etal-2023-dylora}{inproceedings}{}
    \name{author}{4}{}{%
      {{hash=VM}{%
         family={Valipour},
         familyi={V\bibinitperiod},
         given={Mojtaba},
         giveni={M\bibinitperiod},
      }}%
      {{hash=RM}{%
         family={Rezagholizadeh},
         familyi={R\bibinitperiod},
         given={Mehdi},
         giveni={M\bibinitperiod},
      }}%
      {{hash=KI}{%
         family={Kobyzev},
         familyi={K\bibinitperiod},
         given={Ivan},
         giveni={I\bibinitperiod},
      }}%
      {{hash=GA}{%
         family={Ghodsi},
         familyi={G\bibinitperiod},
         given={Ali},
         giveni={A\bibinitperiod},
      }}%
    }
    \name{editor}{2}{}{%
      {{hash=VA}{%
         family={Vlachos},
         familyi={V\bibinitperiod},
         given={Andreas},
         giveni={A\bibinitperiod},
      }}%
      {{hash=AI}{%
         family={Augenstein},
         familyi={A\bibinitperiod},
         given={Isabelle},
         giveni={I\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Association for Computational Linguistics}%
    }
    \strng{namehash}{VM+1}
    \strng{fullhash}{VMRMKIGA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2023}
    \field{labeldatesource}{}
    \field{abstract}{%
    With the ever-growing size of pretrained models (PMs), fine-tuning them has
  become more expensive and resource-hungry. As a remedy, low-rank adapters
  (LoRA) keep the main pretrained weights of the model frozen and just
  introduce some learnable truncated SVD modules (so-called LoRA blocks) to the
  model. While LoRA blocks are parameter-efficient, they suffer from two major
  problems: first, the size of these blocks is fixed and cannot be modified
  after training (for example, if we need to change the rank of LoRA blocks,
  then we need to re-train them from scratch); second, optimizing their rank
  requires an exhaustive search and effort. In this work, we introduce a
  dynamic low-rank adaptation (DyLoRA) technique to address these two problems
  together. Our DyLoRA method trains LoRA blocks for a range of ranks instead
  of a single rank by sorting the representation learned by the adapter module
  at different ranks during training. We evaluate our solution on different
  natural language understanding (GLUE benchmark) and language generation tasks
  (E2E, DART and WebNLG) using different pretrained models such as RoBERTa and
  GPT with different sizes. Our results show that we can train dynamic
  search-free models with DyLoRA at least 4 to 7 times (depending to the task)
  faster than LoRA without significantly compromising performance. Moreover,
  our models can perform consistently well on a much larger range of ranks
  compared to LoRA.%
    }
    \field{booktitle}{Proceedings of the 17th Conference of the European
  Chapter of the Association for Computational Linguistics}
    \verb{doi}
    \verb 10.18653/v1/2023.eacl-main.239
    \endverb
    \field{pages}{3274\bibrangedash 3287}
    \field{title}{{D}y{L}o{RA}: Parameter-Efficient Tuning of Pre-trained
  Models using Dynamic Search-Free Low-Rank Adaptation}
    \verb{url}
    \verb https://aclanthology.org/2023.eacl-main.239
    \endverb
    \list{location}{1}{%
      {Dubrovnik, Croatia}%
    }
    \field{month}{05}
    \field{year}{2023}
  \endentry

  \entry{zhang2023adaptive}{inproceedings}{}
    \name{author}{7}{}{%
      {{hash=ZQ}{%
         family={Zhang},
         familyi={Z\bibinitperiod},
         given={Qingru},
         giveni={Q\bibinitperiod},
      }}%
      {{hash=CM}{%
         family={Chen},
         familyi={C\bibinitperiod},
         given={Minshuo},
         giveni={M\bibinitperiod},
      }}%
      {{hash=BA}{%
         family={Bukharin},
         familyi={B\bibinitperiod},
         given={Alexander},
         giveni={A\bibinitperiod},
      }}%
      {{hash=HP}{%
         family={He},
         familyi={H\bibinitperiod},
         given={Pengcheng},
         giveni={P\bibinitperiod},
      }}%
      {{hash=CY}{%
         family={Cheng},
         familyi={C\bibinitperiod},
         given={Yu},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=CW}{%
         family={Chen},
         familyi={C\bibinitperiod},
         given={Weizhu},
         giveni={W\bibinitperiod},
      }}%
      {{hash=ZT}{%
         family={Zhao},
         familyi={Z\bibinitperiod},
         given={Tuo},
         giveni={T\bibinitperiod},
      }}%
    }
    \strng{namehash}{ZQ+1}
    \strng{fullhash}{ZQCMBAHPCYCWZT1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2023}
    \field{labeldatesource}{}
    \field{booktitle}{The Eleventh International Conference on Learning
  Representations}
    \field{title}{Adaptive Budget Allocation for Parameter-Efficient
  Fine-Tuning}
    \verb{url}
    \verb https://openreview.net/forum?id=lq62uWRJjiY
    \endverb
    \field{year}{2023}
  \endentry

  \entry{chavan2024oneforall}{misc}{}
    \name{author}{5}{}{%
      {{hash=CA}{%
         family={Chavan},
         familyi={C\bibinitperiod},
         given={Arnav},
         giveni={A\bibinitperiod},
      }}%
      {{hash=LZ}{%
         family={Liu},
         familyi={L\bibinitperiod},
         given={Zhuang},
         giveni={Z\bibinitperiod},
      }}%
      {{hash=GD}{%
         family={Gupta},
         familyi={G\bibinitperiod},
         given={Deepak},
         giveni={D\bibinitperiod},
      }}%
      {{hash=XE}{%
         family={Xing},
         familyi={X\bibinitperiod},
         given={Eric},
         giveni={E\bibinitperiod},
      }}%
      {{hash=SZ}{%
         family={Shen},
         familyi={S\bibinitperiod},
         given={Zhiqiang},
         giveni={Z\bibinitperiod},
      }}%
    }
    \strng{namehash}{CA+1}
    \strng{fullhash}{CALZGDXESZ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2024}
    \field{labeldatesource}{}
    \field{title}{One-for-All: Generalized Lo{RA} for Parameter-Efficient
  Fine-tuning}
    \verb{url}
    \verb https://openreview.net/forum?id=K7KQkiHanD
    \endverb
    \field{year}{2024}
  \endentry

  \entry{xu2023tensorgpt}{misc}{}
    \name{author}{3}{}{%
      {{hash=XM}{%
         family={Xu},
         familyi={X\bibinitperiod},
         given={Mingxue},
         giveni={M\bibinitperiod},
      }}%
      {{hash=XYL}{%
         family={Xu},
         familyi={X\bibinitperiod},
         given={Yao\bibnamedelima Lei},
         giveni={Y\bibinitperiod\bibinitdelim L\bibinitperiod},
      }}%
      {{hash=MDP}{%
         family={Mandic},
         familyi={M\bibinitperiod},
         given={Danilo\bibnamedelima P.},
         giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
    }
    \strng{namehash}{XMXYLMDP1}
    \strng{fullhash}{XMXYLMDP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2023}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 2307.00526
    \endverb
    \field{title}{TensorGPT: Efficient Compression of the Embedding Layer in
  LLMs based on the Tensor-Train Decomposition}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2023}
  \endentry

  \entry{lv2023parameter}{misc}{}
    \name{author}{6}{}{%
      {{hash=LK}{%
         family={Lv},
         familyi={L\bibinitperiod},
         given={Kai},
         giveni={K\bibinitperiod},
      }}%
      {{hash=YY}{%
         family={Yang},
         familyi={Y\bibinitperiod},
         given={Yuqing},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=LT}{%
         family={Liu},
         familyi={L\bibinitperiod},
         given={Tengxiao},
         giveni={T\bibinitperiod},
      }}%
      {{hash=GQ}{%
         family={Gao},
         familyi={G\bibinitperiod},
         given={Qinghui},
         giveni={Q\bibinitperiod},
      }}%
      {{hash=GQ}{%
         family={Guo},
         familyi={G\bibinitperiod},
         given={Qipeng},
         giveni={Q\bibinitperiod},
      }}%
      {{hash=QX}{%
         family={Qiu},
         familyi={Q\bibinitperiod},
         given={Xipeng},
         giveni={X\bibinitperiod},
      }}%
    }
    \strng{namehash}{LK+1}
    \strng{fullhash}{LKYYLTGQGQQX1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2023}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 2306.09782
    \endverb
    \field{title}{Full Parameter Fine-tuning for Large Language Models with
  Limited Resources}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2023}
  \endentry

  \entry{yang2023large}{misc}{}
    \name{author}{7}{}{%
      {{hash=YC}{%
         family={Yang},
         familyi={Y\bibinitperiod},
         given={Chengrun},
         giveni={C\bibinitperiod},
      }}%
      {{hash=WX}{%
         family={Wang},
         familyi={W\bibinitperiod},
         given={Xuezhi},
         giveni={X\bibinitperiod},
      }}%
      {{hash=LY}{%
         family={Lu},
         familyi={L\bibinitperiod},
         given={Yifeng},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=LH}{%
         family={Liu},
         familyi={L\bibinitperiod},
         given={Hanxiao},
         giveni={H\bibinitperiod},
      }}%
      {{hash=LQV}{%
         family={Le},
         familyi={L\bibinitperiod},
         given={Quoc\bibnamedelima V.},
         giveni={Q\bibinitperiod\bibinitdelim V\bibinitperiod},
      }}%
      {{hash=ZD}{%
         family={Zhou},
         familyi={Z\bibinitperiod},
         given={Denny},
         giveni={D\bibinitperiod},
      }}%
      {{hash=CX}{%
         family={Chen},
         familyi={C\bibinitperiod},
         given={Xinyun},
         giveni={X\bibinitperiod},
      }}%
    }
    \strng{namehash}{YC+1}
    \strng{fullhash}{YCWXLYLHLQVZDCX1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2023}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 2309.03409
    \endverb
    \field{title}{Large Language Models as Optimizers}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.LG}
    \field{year}{2023}
  \endentry

  \entry{zhu2023survey}{misc}{}
    \name{author}{5}{}{%
      {{hash=ZX}{%
         family={Zhu},
         familyi={Z\bibinitperiod},
         given={Xunyu},
         giveni={X\bibinitperiod},
      }}%
      {{hash=LJ}{%
         family={Li},
         familyi={L\bibinitperiod},
         given={Jian},
         giveni={J\bibinitperiod},
      }}%
      {{hash=LY}{%
         family={Liu},
         familyi={L\bibinitperiod},
         given={Yong},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=MC}{%
         family={Ma},
         familyi={M\bibinitperiod},
         given={Can},
         giveni={C\bibinitperiod},
      }}%
      {{hash=WW}{%
         family={Wang},
         familyi={W\bibinitperiod},
         given={Weiping},
         giveni={W\bibinitperiod},
      }}%
    }
    \strng{namehash}{ZX+1}
    \strng{fullhash}{ZXLJLYMCWW1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2023}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 2308.07633
    \endverb
    \field{title}{A Survey on Model Compression for Large Language Models}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2023}
  \endentry

  \entry{gliwa-etal-2019-samsum}{inproceedings}{}
    \name{author}{4}{}{%
      {{hash=GB}{%
         family={Gliwa},
         familyi={G\bibinitperiod},
         given={Bogdan},
         giveni={B\bibinitperiod},
      }}%
      {{hash=MI}{%
         family={Mochol},
         familyi={M\bibinitperiod},
         given={Iwona},
         giveni={I\bibinitperiod},
      }}%
      {{hash=BM}{%
         family={Biesek},
         familyi={B\bibinitperiod},
         given={Maciej},
         giveni={M\bibinitperiod},
      }}%
      {{hash=WA}{%
         family={Wawer},
         familyi={W\bibinitperiod},
         given={Aleksander},
         giveni={A\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Association for Computational Linguistics}%
    }
    \strng{namehash}{GB+1}
    \strng{fullhash}{GBMIBMWA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2019}
    \field{labeldatesource}{}
    \field{booktitle}{Proceedings of the 2nd Workshop on New Frontiers in
  Summarization}
    \verb{doi}
    \verb 10.18653/v1/D19-5409
    \endverb
    \field{pages}{70\bibrangedash 79}
    \field{title}{{SAMS}um Corpus: A Human-annotated Dialogue Dataset for
  Abstractive Summarization}
    \verb{url}
    \verb https://www.aclweb.org/anthology/D19-5409
    \endverb
    \list{location}{1}{%
      {Hong Kong, China}%
    }
    \field{month}{11}
    \field{year}{2019}
  \endentry

  \entry{lin-2004-rouge}{inproceedings}{}
    \name{author}{1}{}{%
      {{hash=LCY}{%
         family={Lin},
         familyi={L\bibinitperiod},
         given={Chin-Yew},
         giveni={C\bibinithyphendelim Y\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Association for Computational Linguistics}%
    }
    \strng{namehash}{LCY1}
    \strng{fullhash}{LCY1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2004}
    \field{labeldatesource}{}
    \field{booktitle}{Text Summarization Branches Out}
    \field{pages}{74\bibrangedash 81}
    \field{title}{{ROUGE}: A Package for Automatic Evaluation of Summaries}
    \verb{url}
    \verb https://aclanthology.org/W04-1013
    \endverb
    \list{location}{1}{%
      {Barcelona, Spain}%
    }
    \field{month}{07}
    \field{year}{2004}
  \endentry

  \entry{aghajanyan2020intrinsic}{misc}{}
    \name{author}{3}{}{%
      {{hash=AA}{%
         family={Aghajanyan},
         familyi={A\bibinitperiod},
         given={Armen},
         giveni={A\bibinitperiod},
      }}%
      {{hash=ZL}{%
         family={Zettlemoyer},
         familyi={Z\bibinitperiod},
         given={Luke},
         giveni={L\bibinitperiod},
      }}%
      {{hash=GS}{%
         family={Gupta},
         familyi={G\bibinitperiod},
         given={Sonal},
         giveni={S\bibinitperiod},
      }}%
    }
    \strng{namehash}{AAZLGS1}
    \strng{fullhash}{AAZLGS1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2020}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 2012.13255
    \endverb
    \field{title}{Intrinsic Dimensionality Explains the Effectiveness of
  Language Model Fine-Tuning}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.LG}
    \field{year}{2020}
  \endentry

  \entry{lewis2019bart}{misc}{}
    \name{author}{8}{}{%
      {{hash=LM}{%
         family={Lewis},
         familyi={L\bibinitperiod},
         given={Mike},
         giveni={M\bibinitperiod},
      }}%
      {{hash=LY}{%
         family={Liu},
         familyi={L\bibinitperiod},
         given={Yinhan},
         giveni={Y\bibinitperiod},
      }}%
      {{hash=GN}{%
         family={Goyal},
         familyi={G\bibinitperiod},
         given={Naman},
         giveni={N\bibinitperiod},
      }}%
      {{hash=GM}{%
         family={Ghazvininejad},
         familyi={G\bibinitperiod},
         given={Marjan},
         giveni={M\bibinitperiod},
      }}%
      {{hash=MA}{%
         family={Mohamed},
         familyi={M\bibinitperiod},
         given={Abdelrahman},
         giveni={A\bibinitperiod},
      }}%
      {{hash=LO}{%
         family={Levy},
         familyi={L\bibinitperiod},
         given={Omer},
         giveni={O\bibinitperiod},
      }}%
      {{hash=SV}{%
         family={Stoyanov},
         familyi={S\bibinitperiod},
         given={Ves},
         giveni={V\bibinitperiod},
      }}%
      {{hash=ZL}{%
         family={Zettlemoyer},
         familyi={Z\bibinitperiod},
         given={Luke},
         giveni={L\bibinitperiod},
      }}%
    }
    \strng{namehash}{LM+1}
    \strng{fullhash}{LMLYGNGMMALOSVZL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2019}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 1910.13461
    \endverb
    \field{title}{BART: Denoising Sequence-to-Sequence Pre-training for Natural
  Language Generation, Translation, and Comprehension}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2019}
  \endentry

  \entry{devlin2019bert}{misc}{}
    \name{author}{4}{}{%
      {{hash=DJ}{%
         family={Devlin},
         familyi={D\bibinitperiod},
         given={Jacob},
         giveni={J\bibinitperiod},
      }}%
      {{hash=CMW}{%
         family={Chang},
         familyi={C\bibinitperiod},
         given={Ming-Wei},
         giveni={M\bibinithyphendelim W\bibinitperiod},
      }}%
      {{hash=LK}{%
         family={Lee},
         familyi={L\bibinitperiod},
         given={Kenton},
         giveni={K\bibinitperiod},
      }}%
      {{hash=TK}{%
         family={Toutanova},
         familyi={T\bibinitperiod},
         given={Kristina},
         giveni={K\bibinitperiod},
      }}%
    }
    \strng{namehash}{DJ+1}
    \strng{fullhash}{DJCMWLKTK1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2019}
    \field{labeldatesource}{}
    \verb{eprint}
    \verb 1810.04805
    \endverb
    \field{title}{BERT: Pre-training of Deep Bidirectional Transformers for
  Language Understanding}
    \field{eprinttype}{arXiv}
    \field{eprintclass}{cs.CL}
    \field{year}{2019}
  \endentry
\enddatalist
\endinput
